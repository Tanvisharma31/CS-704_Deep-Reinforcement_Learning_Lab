{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Layer Perceptron Model 1 : **IRIS Dataset**"
      ],
      "metadata": {
        "id": "ZsHQRN9acLCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ffMRQjUcb6O-"
      },
      "outputs": [],
      "source": [
        "# import necessary files\n",
        "from sklearn.datasets import load_iris # import the iris dataset\n",
        "from sklearn.model_selection import train_test_split # import train_test_split to split the data\n",
        "from keras.models import Sequential # import Sequential to build the model\n",
        "from keras.layers import Dense # import Dense to add layers to the model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load Dataset\n",
        "data=load_iris() # load the iris dataset"
      ],
      "metadata": {
        "id": "o6uThAaNcOOS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=data.data # features\n",
        "y=data.target # labels"
      ],
      "metadata": {
        "id": "pZ3a3GFjcRni"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.size # print the size of the labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D54DjEX4cTUO",
        "outputId": "23a1d28f-84e5-498e-a691-d1f39665f3f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # import StandardScaler to scale the data and OneHotEncoder to encode the labels\n"
      ],
      "metadata": {
        "id": "LQ7XiELFcVs8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=StandardScaler() # initialize the scaler\n",
        "x_scaled=scaler.fit_transform(x) # scale the features"
      ],
      "metadata": {
        "id": "-pE-CSHWcdSB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x # print the original features\n",
        "x_scaled # print the scaled features"
      ],
      "metadata": {
        "id": "89-668DBcrvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6e4d45-1dc2-4214-b086-a6b30e144760"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
              "        -9.20547742e-01],\n",
              "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
              "        -7.88915558e-01],\n",
              "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
              "         2.64141916e-01],\n",
              "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
              "         3.95774101e-01],\n",
              "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
              "         3.95774101e-01],\n",
              "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
              "         5.27406285e-01],\n",
              "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
              "         1.32509732e-01],\n",
              "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
              "         2.64141916e-01],\n",
              "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
              "         2.64141916e-01],\n",
              "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
              "         1.32509732e-01],\n",
              "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
              "         2.64141916e-01],\n",
              "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
              "        -1.30754636e-01],\n",
              "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
              "         8.77547895e-04],\n",
              "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
              "         2.64141916e-01],\n",
              "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
              "         2.64141916e-01],\n",
              "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
              "         6.59038469e-01],\n",
              "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
              "        -2.62386821e-01],\n",
              "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
              "        -1.30754636e-01],\n",
              "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
              "        -2.62386821e-01],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
              "         8.77547895e-04],\n",
              "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
              "         5.27406285e-01],\n",
              "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
              "         5.27406285e-01],\n",
              "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
              "         1.32509732e-01],\n",
              "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
              "         1.32509732e-01],\n",
              "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
              "         1.32509732e-01],\n",
              "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
              "         8.77547895e-04],\n",
              "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
              "         2.64141916e-01],\n",
              "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
              "         8.77547895e-04],\n",
              "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
              "        -2.62386821e-01],\n",
              "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
              "         1.32509732e-01],\n",
              "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
              "         8.77547895e-04],\n",
              "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
              "         1.32509732e-01],\n",
              "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
              "        -1.30754636e-01],\n",
              "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
              "         1.71209594e+00],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
              "         1.18556721e+00],\n",
              "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
              "         1.31719939e+00],\n",
              "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
              "         1.18556721e+00],\n",
              "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
              "         6.59038469e-01],\n",
              "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
              "         1.71209594e+00],\n",
              "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
              "         1.05393502e+00],\n",
              "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
              "         1.18556721e+00],\n",
              "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
              "         1.05393502e+00],\n",
              "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
              "         1.58046376e+00],\n",
              "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
              "         1.44883158e+00],\n",
              "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
              "         1.31719939e+00],\n",
              "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
              "         1.44883158e+00],\n",
              "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
              "         1.44883158e+00],\n",
              "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
              "         1.05393502e+00],\n",
              "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
              "         1.05393502e+00],\n",
              "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
              "         1.18556721e+00],\n",
              "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
              "         1.18556721e+00],\n",
              "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
              "         5.27406285e-01],\n",
              "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
              "         9.22302838e-01],\n",
              "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
              "         1.05393502e+00],\n",
              "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
              "         1.31719939e+00],\n",
              "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
              "         2.64141916e-01],\n",
              "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
              "         1.44883158e+00],\n",
              "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
              "         1.58046376e+00],\n",
              "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
              "         1.18556721e+00],\n",
              "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
              "         1.58046376e+00],\n",
              "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
              "         1.44883158e+00],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
              "         1.44883158e+00],\n",
              "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
              "         1.71209594e+00],\n",
              "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
              "         1.44883158e+00],\n",
              "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
              "         1.05393502e+00],\n",
              "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
              "         1.44883158e+00],\n",
              "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
              "         7.90670654e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical # import to_categorical to one hot encode the labels\n",
        "y_encoded=to_categorical(y) # one hot encode the labels"
      ],
      "metadata": {
        "id": "xDfkCINdcsis"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x_scaled,y_encoded,test_size=0.2) # split into train and test\n"
      ],
      "metadata": {
        "id": "xKqOBh_1cwx9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential() # initialize the model\n",
        "model.add(Dense(32,input_shape=(x_train.shape[1],),activation='relu')) # add a dense layer with relu activation\n",
        "model.add(Dense(3,activation='softmax')) # add the output layer with softmax activation\n"
      ],
      "metadata": {
        "id": "Vzwkclb-czgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac6a48f-a05e-4162-a570-e167c01803ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # compile the model\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yi1jVhv6c39z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "vGbPyXcrc40K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "ae0cb2bf-da3c-4cc9-99ed-9224e7bbf600"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m99\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m259\u001b[0m (1.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">259</span> (1.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m259\u001b[0m (1.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">259</span> (1.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(x_train,y_train,epochs=50)"
      ],
      "metadata": {
        "id": "6UdKx1c7c9vX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377d677d-0fb3-4f5a-c5f2-bd2bd8590035"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1810 - loss: 1.2983\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1925 - loss: 1.2407 \n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1806 - loss: 1.2002 \n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1981 - loss: 1.1281 \n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2065 - loss: 1.1191\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2998 - loss: 1.1037 \n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3963 - loss: 1.0398 \n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4002 - loss: 0.9956 \n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4900 - loss: 0.9697 \n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5100 - loss: 0.9403 \n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5394 - loss: 0.9083 \n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5650 - loss: 0.8739 \n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5527 - loss: 0.8755 \n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5869 - loss: 0.8418 \n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6604 - loss: 0.8162 \n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7208 - loss: 0.7852 \n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.7444  \n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7312 - loss: 0.7580 \n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7648 - loss: 0.7041 \n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.7108 \n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7681 - loss: 0.6965  \n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.6309 \n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.6407 \n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.6233 \n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7656 - loss: 0.6265 \n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.5719 \n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.5866 \n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.5815 \n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 0.5621 \n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8131 - loss: 0.5453 \n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.5033 \n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.5027 \n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8454 - loss: 0.4964 \n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4907 \n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4869 \n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4759 \n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4612 \n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.4609 \n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8363 - loss: 0.4344 \n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8331 - loss: 0.4335 \n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.4451 \n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8406 - loss: 0.4072 \n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4268 \n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.4228 \n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8710 - loss: 0.3829  \n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3916 \n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8744 - loss: 0.3793 \n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.4073 \n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.3983 \n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.3607 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x792bd5b16980>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # evaluate the model\n",
        "\n",
        "loss,accuracy=model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "J2HFhH1hc-d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef774b8-b245-447e-d8e6-82ef9d362aee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8667 - loss: 0.2728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the loss & accuracy\n",
        "print('loss: ',loss)\n",
        "print('accuracy',accuracy)"
      ],
      "metadata": {
        "id": "gCWhIajidAoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a505be22-7aca-4975-8993-f5fe57ce4f00"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  0.27284812927246094\n",
            "accuracy 0.8666666746139526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation Using **Pytorch**\n"
      ],
      "metadata": {
        "id": "87YBhi_klh7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "x = data.data\n",
        "y = data.target\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# One-hot encode the labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader for batch processing\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define the MLP model in PyTorch\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = x_train.shape[1]\n",
        "hidden_size = 32\n",
        "output_size = y_train.shape[1]\n",
        "model = MLP(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the loss for every epoch\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(x_test_tensor)\n",
        "    test_loss = criterion(test_outputs, y_test_tensor).item()\n",
        "    _, predicted = torch.max(test_outputs, 1)\n",
        "    _, actual = torch.max(y_test_tensor, 1)\n",
        "    accuracy = (predicted == actual).float().mean().item()\n",
        "\n",
        "print(f'Loss: {test_loss:.4f}')\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "ZMmQ7ulhdC94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145e4cd2-c59a-4eb5-a01e-5c459a8698d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 1.0244\n",
            "Epoch [2/50], Loss: 1.0242\n",
            "Epoch [3/50], Loss: 1.0197\n",
            "Epoch [4/50], Loss: 1.0085\n",
            "Epoch [5/50], Loss: 0.9382\n",
            "Epoch [6/50], Loss: 0.9386\n",
            "Epoch [7/50], Loss: 0.9694\n",
            "Epoch [8/50], Loss: 0.8747\n",
            "Epoch [9/50], Loss: 0.8511\n",
            "Epoch [10/50], Loss: 0.7893\n",
            "Epoch [11/50], Loss: 0.8148\n",
            "Epoch [12/50], Loss: 0.7984\n",
            "Epoch [13/50], Loss: 0.7795\n",
            "Epoch [14/50], Loss: 0.7816\n",
            "Epoch [15/50], Loss: 0.8884\n",
            "Epoch [16/50], Loss: 0.7004\n",
            "Epoch [17/50], Loss: 0.6900\n",
            "Epoch [18/50], Loss: 0.8552\n",
            "Epoch [19/50], Loss: 0.7947\n",
            "Epoch [20/50], Loss: 0.7807\n",
            "Epoch [21/50], Loss: 0.6921\n",
            "Epoch [22/50], Loss: 0.8414\n",
            "Epoch [23/50], Loss: 0.8083\n",
            "Epoch [24/50], Loss: 0.6869\n",
            "Epoch [25/50], Loss: 0.7497\n",
            "Epoch [26/50], Loss: 0.7120\n",
            "Epoch [27/50], Loss: 0.6226\n",
            "Epoch [28/50], Loss: 0.8811\n",
            "Epoch [29/50], Loss: 0.7420\n",
            "Epoch [30/50], Loss: 0.7096\n",
            "Epoch [31/50], Loss: 0.7387\n",
            "Epoch [32/50], Loss: 0.7420\n",
            "Epoch [33/50], Loss: 0.6246\n",
            "Epoch [34/50], Loss: 0.5868\n",
            "Epoch [35/50], Loss: 0.6831\n",
            "Epoch [36/50], Loss: 0.6484\n",
            "Epoch [37/50], Loss: 0.7533\n",
            "Epoch [38/50], Loss: 0.7220\n",
            "Epoch [39/50], Loss: 0.6498\n",
            "Epoch [40/50], Loss: 0.7610\n",
            "Epoch [41/50], Loss: 0.7432\n",
            "Epoch [42/50], Loss: 0.7251\n",
            "Epoch [43/50], Loss: 0.6773\n",
            "Epoch [44/50], Loss: 0.6601\n",
            "Epoch [45/50], Loss: 0.6362\n",
            "Epoch [46/50], Loss: 0.6352\n",
            "Epoch [47/50], Loss: 0.6494\n",
            "Epoch [48/50], Loss: 0.7661\n",
            "Epoch [49/50], Loss: 0.6953\n",
            "Epoch [50/50], Loss: 0.6794\n",
            "Loss: 0.6379\n",
            "Accuracy: 96.67%\n"
          ]
        }
      ]
    }
  ]
}