{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GaussianNoise\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784) / 255.0\n",
    "X_test = X_test.reshape(-1, 784) / 255.0\n",
    "\n",
    "# Function to create a baseline autoencoder model\n",
    "def create_autoencoder(l2_reg=0, dropout_rate=0, noise_factor=0):\n",
    "    input_img = Input(shape=(784,))\n",
    "    \n",
    "    # Optional noise injection layer\n",
    "    if noise_factor > 0:\n",
    "        noisy_input = GaussianNoise(noise_factor)(input_img)\n",
    "    else:\n",
    "        noisy_input = input_img\n",
    "    \n",
    "    # Encoder with optional L2 regularization and dropout\n",
    "    encoded = Dense(128, activation='relu', kernel_regularizer=l2(l2_reg))(noisy_input)\n",
    "    if dropout_rate > 0:\n",
    "        encoded = Dropout(dropout_rate)(encoded)\n",
    "    \n",
    "    encoded = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg))(encoded)\n",
    "    encoded_output = Dense(32, activation='relu', kernel_regularizer=l2(l2_reg))(encoded)\n",
    "    \n",
    "    # Decoder with optional L2 regularization\n",
    "    decoded = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg))(encoded_output)\n",
    "    decoded = Dense(128, activation='relu', kernel_regularizer=l2(l2_reg))(decoded)\n",
    "    decoded_output = Dense(784, activation='sigmoid')(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded_output)\n",
    "    return autoencoder\n",
    "\n",
    "# Function to train and evaluate autoencoder\n",
    "def train_autoencoder(autoencoder, epochs=10):\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mse')\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=256, shuffle=True, validation_data=(X_test, X_test))\n",
    "    return history\n",
    "\n",
    "# Define different regularization techniques\n",
    "techniques = {\n",
    "    'Baseline': (0, 0, 0),\n",
    "    'L2 Regularization': (0.001, 0, 0),\n",
    "    'Dropout': (0, 0.3, 0),\n",
    "    'Noise Injection': (0, 0, 0.3)\n",
    "}\n",
    "\n",
    "# Train autoencoders with each regularization technique and record history\n",
    "histories = {}\n",
    "for technique, (l2_reg, dropout_rate, noise_factor) in techniques.items():\n",
    "    print(f\"\\nTraining with {technique}...\")\n",
    "    autoencoder = create_autoencoder(l2_reg=l2_reg, dropout_rate=dropout_rate, noise_factor=noise_factor)\n",
    "    history = train_autoencoder(autoencoder, epochs=10)\n",
    "    histories[technique] = history.history['val_loss']\n",
    "\n",
    "# Plot validation loss for comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "for technique, val_loss in histories.items():\n",
    "    plt.plot(val_loss, label=technique)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Validation Loss Across Different Regularization Techniques')\n",
    "plt.show()\n",
    "\n",
    "# Visualize reconstruction quality on test data for each technique\n",
    "def visualize_reconstructions(technique):\n",
    "    autoencoder = create_autoencoder(*techniques[technique])\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=10, batch_size=256, shuffle=True)\n",
    "    \n",
    "    decoded_imgs = autoencoder.predict(X_test[:10])\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    for i in range(10):\n",
    "        # Display original\n",
    "        ax = plt.subplot(2, 10, i + 1)\n",
    "        plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        # Display reconstruction\n",
    "        ax = plt.subplot(2, 10, i + 1 + 10)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Reconstruction with {technique}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize reconstructions for each technique\n",
    "for technique in techniques.keys():\n",
    "    visualize_reconstructions(technique)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
